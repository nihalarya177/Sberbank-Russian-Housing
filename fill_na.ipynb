{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_stats(sub_area, sub_col, method):\n",
    "    if(method == 'mode'):\n",
    "        res = train[(train['sub_area'] == sub_area)][sub_col].mode()\n",
    "    elif(method == 'median'):\n",
    "        res = train[(train['sub_area'] == sub_area)][sub_col].median()\n",
    "    elif(method == 'mean'):\n",
    "        res = train[(train['sub_area'] == sub_area)][sub_col].mean()\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill trivials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fill hospital bed with 0 \n",
    "train['hospital_beds_raion'] = train['hospital_beds_raion'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with mean for the district\n",
    "# fill with mode of district as most common rail ID's\n",
    "train['ID_railroad_station_walk'] = train.groupby(['sub_area'], sort=False)['ID_railroad_station_walk'].apply(lambda x: x.fillna(x.mode()[0])) \n",
    "train['metro_min_walk'] = train.groupby(['sub_area'], sort=False)['metro_min_walk'].apply(lambda x: x.fillna(x.mean())) \n",
    "train['metro_km_walk'] = train.groupby(['sub_area'], sort=False)['metro_km_walk'].apply(lambda x: x.fillna(x.mean()))\n",
    "train['railroad_station_walk_km'] = train.groupby(['sub_area'], sort=False)['railroad_station_walk_km'].apply(lambda x: x.fillna(x.mean()))\n",
    "train['railroad_station_walk_min'] = train.groupby(['sub_area'], sort=False)['railroad_station_walk_min'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified that these neighbourhoods have no schools/preschools so we fill null\n",
    "train['school_quota'] = train['school_quota'].fillna(value=0)\n",
    "train['preschool_quota'] = train['preschool_quota'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['material'] = train.groupby(['sub_area'], sort=False)['material'].apply(lambda x: x.fillna(x.mode()[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Build_count_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_build_index(sub_area, period):\n",
    "    return ck[c.index(sub_area)][period]\n",
    "\n",
    "def get_sum(row):\n",
    "    row_sum = (row['build_count_before_1920']+\n",
    "        row['build_count_1921-1945'] + \n",
    "        row['build_count_1946-1970']+\n",
    "        row['build_count_1971-1995']+\n",
    "        row['build_count_after_1995']\n",
    "    )\n",
    "    return row_sum\n",
    "\n",
    "def get_year_built(row):\n",
    "    periods = [row['build_count_before_1920'],row['build_count_1921-1945'],row['build_count_1946-1970'],row['build_count_1971-1995'],row['build_count_after_1995']]\n",
    "    max_val = max(periods)\n",
    "    max_ind = periods.index(max_val)\n",
    "    if(max_val==0):\n",
    "        return row['timestamp_year'].astype(float)\n",
    "    else:\n",
    "        return mean_build_year[max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material\n",
    "df['material'] = df.groupby(['sub_area'], sort=False)['material'].apply(lambda x: x.fillna(x.mode()[0])) \n",
    "\n",
    "# Build Count\n",
    "df['build_count_block'] = df['build_count_block'].fillna((np.ceil(df['build_count_block'].mean())))                                  \n",
    "df['build_count_wood'] = df['build_count_wood'].fillna(value = np.ceil(df['build_count_wood'].mean()))\n",
    "df['build_count_frame'] = df['build_count_frame'].fillna(value = np.ceil(df['build_count_frame'].mean()))\n",
    "df['build_count_brick'] = df['build_count_brick'].fillna(value = np.ceil(df['build_count_brick'].mean()))\n",
    "df['build_count_monolith'] = df['build_count_monolith'].fillna(value = np.ceil(df['build_count_monolith'].mean()))\n",
    "df['build_count_panel'] = df['build_count_panel'].fillna(value = np.ceil(df['build_count_panel'].mean()))\n",
    "df['build_count_foam'] = df['build_count_foam'].fillna(value = np.ceil(df['build_count_foam'].mean()))\n",
    "df['build_count_slag'] = df['build_count_slag'].fillna(value = np.ceil(df['build_count_slag'].mean()))\n",
    "df['build_count_mix'] = df['build_count_mix'].fillna(value = np.ceil(df['build_count_mix'].mean()))\n",
    "\n",
    "build_count_sum = (np.ceil(df['build_count_block'].mean())+\n",
    "   np.ceil(df['build_count_wood'].mean())+\n",
    "    np.ceil(df['build_count_frame'].mean())+       \n",
    "    np.ceil(df['build_count_brick'].mean())+\n",
    "    np.ceil(df['build_count_monolith'].mean())+\n",
    "    np.ceil(df['build_count_panel'].mean())+\n",
    "    np.ceil(df['build_count_foam'].mean())+               \n",
    "    np.ceil(df['build_count_slag'].mean())+\n",
    "    np.ceil(df['build_count_mix'].mean())                \n",
    ")\n",
    "\n",
    "# Build Count Raion\n",
    "df['raion_build_count_with_material_info'] = df['raion_build_count_with_material_info'].fillna(value=build_count_sum)\n",
    "\n",
    "c = list(df[df['build_count_1921-1945'].isna()]['sub_area'].unique())\n",
    "\n",
    "ck = np.ones(shape=(15,5))\n",
    "\n",
    "for i in range(len(c)):\n",
    "    build_years = list(df[df['sub_area'] == c[i]]['build_year'].dropna())\n",
    "    for j in range(len(build_years)):\n",
    "        if(build_years[j]<=1920):\n",
    "            ck[i][0] += 1\n",
    "        elif(1920<build_years[j]<=1945):\n",
    "            ck[i][1] += 1\n",
    "        elif(1945<build_years[j]<=1970):\n",
    "            ck[i][2] += 1\n",
    "        elif(1970<build_years[j]<=1995):\n",
    "            ck[i][3] += 1\n",
    "        else:\n",
    "            ck[i][4] += 1\n",
    "            \n",
    "df['build_count_before_1920'] = df.apply(\n",
    "    lambda row: get_build_index(row['sub_area'], 0) if np.isnan(row['build_count_before_1920']) else row['build_count_before_1920'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['build_count_1921-1945'] = df.apply(\n",
    "    lambda row: get_build_index(row['sub_area'], 1) if np.isnan(row['build_count_1921-1945']) else row['build_count_1921-1945'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['build_count_1946-1970'] = df.apply(\n",
    "    lambda row: get_build_index(row['sub_area'], 2) if np.isnan(row['build_count_1946-1970']) else row['build_count_1946-1970'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['build_count_1971-1995'] = df.apply(\n",
    "    lambda row: get_build_index(row['sub_area'], 3) if np.isnan(row['build_count_1971-1995']) else row['build_count_1971-1995'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['build_count_after_1995'] = df.apply(\n",
    "    lambda row: get_build_index(row['sub_area'], 4) if np.isnan(row['build_count_after_1995']) else row['build_count_after_1995'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['raion_build_count_with_builddate_info'] = df.apply(\n",
    "    lambda row: get_sum(row) if np.isnan(row['raion_build_count_with_builddate_info']) else row['raion_build_count_with_builddate_info'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['build_year'] = df.apply(\n",
    "    lambda row: np.NaN if ((row['build_year']<1471) | (row['build_year']>2020)) else row['build_year'],\n",
    "    axis=1\n",
    ") # set na for bad indexes\n",
    "\n",
    "mean_build_year = np.ceil(\n",
    "[\n",
    "   df[df['build_year']<=1920]['build_year'].mean(),\n",
    "   df[(df['build_year']>1920) & (df['build_year']<=1945)]['build_year'].mean(),\n",
    "   df[(df['build_year']>1945) & (df['build_year']<=1970)]['build_year'].mean(),\n",
    "   df[(df['build_year']>1970) & (df['build_year']<=1995)]['build_year'].mean(),\n",
    "   df[df['build_year']>1995]['build_year'].mean()\n",
    "    \n",
    "]) # get mean build year for each period\n",
    "\n",
    "df['build_year'] = df.apply(\n",
    "    lambda row: get_year_built(row) if np.isnan(row['build_year']) else row['build_year'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['prom_part_5000'] = df.groupby(['sub_area'], sort=False)['prom_part_5000'].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "cafe_ranges = ['500', '1000', '1500', '2000', '3000', '5000' ]\n",
    "\n",
    "for cafe_range in cafe_ranges:\n",
    "    df['cafe_sum_{0}_min_price_avg'.format(cafe_range)] = df.groupby(['sub_area'], sort=False)['cafe_sum_{0}_min_price_avg'.format(cafe_range)].apply(lambda x: x.fillna(x.mean())) \n",
    "    df['cafe_sum_{0}_max_price_avg'.format(cafe_range)] = df.groupby(['sub_area'], sort=False)['cafe_sum_{0}_max_price_avg'.format(cafe_range)].apply(lambda x: x.fillna(x.mean())) \n",
    "    df['cafe_avg_price_{0}'.format(cafe_range)] = df.groupby(['sub_area'], sort=False)['cafe_avg_price_{0}'.format(cafe_range)].apply(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    df['cafe_sum_{0}_min_price_avg'.format(cafe_range)] = df['cafe_sum_{0}_min_price_avg'.format(cafe_range)].fillna(value=df['cafe_sum_{0}_min_price_avg'.format(cafe_range)].mean())\n",
    "    df['cafe_sum_{0}_max_price_avg'.format(cafe_range)] = df['cafe_sum_{0}_max_price_avg'.format(cafe_range)].fillna(value=df['cafe_sum_{0}_max_price_avg'.format(cafe_range)].mean())\n",
    "    df['cafe_avg_price_{0}'.format(cafe_range)] = df['cafe_avg_price_{0}'.format(cafe_range)].fillna(value=df['cafe_avg_price_{0}'.format(cafe_range)].mean())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill build_count_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill build_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill prom_part / cafe_sum vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prom_part_5000'] = train.groupby(['sub_area'], sort=False)['prom_part_5000'].apply(lambda x: x.fillna(x.mode()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_ranges = ['500', '1000', '1500', '2000', '3000', '5000' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cafe_range in cafe_ranges:\n",
    "    train['cafe_sum_{0}_min_price_avg'.format(cafe_range)] = train.groupby(['sub_area'], sort=False)['cafe_sum_{0}_min_price_avg'.format(cafe_range)].apply(lambda x: x.fillna(x.mean())) \n",
    "    train['cafe_sum_{0}_max_price_avg'.format(cafe_range)] = train.groupby(['sub_area'], sort=False)['cafe_sum_{0}_max_price_avg'.format(cafe_range)].apply(lambda x: x.fillna(x.mean())) \n",
    "    train['cafe_avg_price_{0}'.format(cafe_range)] = train.groupby(['sub_area'], sort=False)['cafe_avg_price_{0}'.format(cafe_range)].apply(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    train['cafe_sum_{0}_min_price_avg'.format(cafe_range)] = train['cafe_sum_{0}_min_price_avg'.format(cafe_range)].fillna(value=train['cafe_sum_{0}_min_price_avg'.format(cafe_range)].mean())\n",
    "    train['cafe_sum_{0}_max_price_avg'.format(cafe_range)] = train['cafe_sum_{0}_max_price_avg'.format(cafe_range)].fillna(value=train['cafe_sum_{0}_max_price_avg'.format(cafe_range)].mean())\n",
    "    train['cafe_avg_price_{0}'.format(cafe_range)] = train['cafe_avg_price_{0}'.format(cafe_range)].fillna(value=train['cafe_avg_price_{0}'.format(cafe_range)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'floor': 167,\n",
       " 'life_sq': 6383,\n",
       " 'max_floor': 9572,\n",
       " 'num_room': 9572,\n",
       " 'kitch_sq': 9572,\n",
       " 'state': 13559}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_dict = {}\n",
    "for col in train.columns:\n",
    "    if( train[col].isnull().sum()>0):\n",
    "        null_dict[col] = train[col].isnull().sum()\n",
    "        \n",
    "{k: v for k, v in sorted(null_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_type'] = df.groupby(['sub_area'], sort=False)['product_type'].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "df['green_part_2000'] = df.groupby(['sub_area'], sort=False)['green_part_2000'].apply(lambda x: x.fillna(x.mode()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
